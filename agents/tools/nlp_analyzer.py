# -*- coding: utf-8 -*-
"""
NLP Analyzer - Sembi IQ Style Test Case Generation
====================================================
Metinden akÄ±llÄ± test senaryolarÄ± Ã§Ä±karmak iÃ§in NLP analizi
"""

import re
import sys
import os
from typing import List, Dict, Any, Tuple
from collections import Counter

# NLP kÃ¼tÃ¼phaneleri
try:
    import spacy
    from spacy.tokens import Doc
except ImportError:
    print("âš ï¸ spaCy yÃ¼klenmediÄŸi. LÃ¼tfen Ã§alÄ±ÅŸtÄ±r: python -m spacy download tr_core_news_sm")
    spacy = None

try:
    from transformers import pipeline
except ImportError:
    print("âš ï¸ Transformers yÃ¼klenmediÄŸi")
    pipeline = None

import nltk
from nltk.sentiment import SentimentIntensityAnalyzer
from nltk.tokenize import sent_tokenize

# NLTK data indir
try:
    nltk.data.find('vader_lexicon')
except LookupError:
    nltk.download('vader_lexicon', quiet=True)
try:
    nltk.data.find('punkt')
except LookupError:
    nltk.download('punkt', quiet=True)


class NLPAnalyzer:
    """NLP destekli test senaryo analizi"""
    
    def __init__(self):
        """Analyzer'Ä± baÅŸlat"""
        self.nlp = None
        self.ner_model = None
        self.zero_shot_classifier = None
        self.sia = SentimentIntensityAnalyzer()
        self._initialize_models()
        
        # Anahtar kelimeler
        self.action_keywords = {
            'NAVIGATE': ['git', 'git', 'aÃ§', 'ziyaret et', 'yÃ¶nlendir', 'page', 'url', 'tarayÄ±cÄ±'],
            'INPUT': ['gir', 'yazÄ±', 'doldur', 'form', 'alanÄ±', 'ÅŸifre', 'email', 'text', 'input'],
            'CLICK': ['tÄ±kla', 'klik', 'basÄ±l', 'seÃ§', 'button', 'buton', 'link'],
            'VERIFY': ['doÄŸrula', 'kontrol', 'kontrol et', 'kontrol et', 'assert', 'gÃ¶ster', 'gÃ¶rÃ¼n', 'expect'],
            'WAIT': ['bekle', 'yÃ¼klendi', 'loading', 'await'],
            'SCROLL': ['kaydÄ±r', 'scroll', 'aÅŸaÄŸÄ±', 'yukarÄ±'],
            'UPLOAD': ['yÃ¼kle', 'upload', 'dosya', 'attach'],
            'DELETE': ['sil', 'delete', 'remove', 'kaldÄ±r'],
            'EDIT': ['dÃ¼zenle', 'edit', 'update', 'deÄŸiÅŸtir', 'deÄŸiÅŸtir'],
        }
        
        # Risk seviyesi anahtar kelimeleri
        self.risk_keywords = {
            'CRITICAL': ['gÃ¼venlik', 'ÅŸifre', 'tokib', 'Ã¶deme', 'kredi', 'kart', 'kimlik', 'saldÄ±rÄ±', 'hack', 'injection', 'sql'],
            'HIGH': ['oturum', 'session', 'login', 'logout', 'authorize', 'permission', 'hata', 'error', 'validation'],
            'MEDIUM': ['arama', 'search', 'filtreleme', 'sorting', 'pagination'],
            'LOW': ['gÃ¶rÃ¼nÃ¼m', 'ui', 'layout', 'display', 'format'],
        }
        
    def _initialize_models(self):
        """Modelleri baÅŸlat"""
        try:
            if spacy:
                try:
                    self.nlp = spacy.load('tr_core_news_sm')
                    print("âœ… spaCy TÃ¼rkÃ§e modeli yÃ¼klendi")
                except OSError:
                    print("âš ï¸ spaCy TÃ¼rkÃ§e modeli yÃ¼klenemiyor. Ä°ngilizce kullanÄ±lacak.")
                    self.nlp = spacy.load('en_core_web_sm')
        except Exception as e:
            print(f"âš ï¸ spaCy model baÅŸlatma hatasÄ±: {e}")
        
        # NER modeli (Entity Recognition)
        try:
            if pipeline:
                self.ner_model = pipeline("ner", model="dbmdz/bert-base-turkish-cased", 
                                         aggregation_strategy="simple")
                print("âœ… BERT NER modeli yÃ¼klendi")
        except Exception as e:
            print(f"âš ï¸ BERT model baÅŸlatma hatasÄ±: {e}")
    
    def analyze_requirements(self, text: str) -> Dict[str, Any]:
        """
        Gereksinimleri kapsamlÄ± olarak analiz et
        
        Args:
            text: Analiz edilecek metin
            
        Returns:
            Analiz sonuÃ§larÄ±
        """
        results = {
            'original_text': text,
            'entities': self._extract_entities(text),
            'actions': self._extract_actions(text),
            'risks': self._analyze_risks(text),
            'sentiment': self._analyze_sentiment(text),
            'test_types': self._determine_test_types(text),
            'edge_cases': self._identify_edge_cases(text),
            'user_flows': self._extract_user_flows(text),
        }
        return results
    
    def _extract_entities(self, text: str) -> List[Dict[str, str]]:
        """Metinden entity'leri Ã§Ä±kar (kullanÄ±cÄ±, Ã¼rÃ¼n, sayfa, vb.)"""
        entities = []
        
        # Regex-based extraction
        patterns = {
            'USER': r'(kullanÄ±cÄ±|user|admin|guest)',
            'PAGE': r'(sayfa|page|dashboard|menu|panel)',
            'FIELD': r'(alanÄ±|field|input|textbox)',
            'PRODUCT': r'(Ã¼rÃ¼n|product|item|kategori)',
            'ACTION': r'(iÅŸlem|process|action|gÃ¶rev)',
        }
        
        for entity_type, pattern in patterns.items():
            matches = re.finditer(pattern, text, re.IGNORECASE)
            for match in matches:
                entities.append({
                    'type': entity_type,
                    'value': match.group(),
                    'position': match.start()
                })
        
        # spaCy NER
        if self.nlp:
            try:
                doc = self.nlp(text[:1000])  # Ä°lk 1000 char
                for ent in doc.ents:
                    entities.append({
                        'type': ent.label_,
                        'value': ent.text,
                        'position': ent.start_char
                    })
            except Exception as e:
                print(f"âš ï¸ spaCy NER hatasÄ±: {e}")
        
        # Duplikat kaldÄ±r
        unique_entities = []
        seen = set()
        for ent in entities:
            key = (ent['type'], ent['value'].lower())
            if key not in seen:
                seen.add(key)
                unique_entities.append(ent)
        
        return unique_entities
    
    def _extract_actions(self, text: str) -> List[Dict[str, Any]]:
        """Metinden eylemleri Ã§Ä±kar"""
        actions = []
        sentences = sent_tokenize(text)
        
        for i, sentence in enumerate(sentences):
            for action_type, keywords in self.action_keywords.items():
                for keyword in keywords:
                    if keyword.lower() in sentence.lower():
                        actions.append({
                            'type': action_type,
                            'keyword': keyword,
                            'sentence': sentence.strip(),
                            'order': i
                        })
                        break
        
        # Duplikat ve sÄ±ra kontrol
        actions = sorted(list({(a['sentence']): a for a in actions}.values()), 
                        key=lambda x: x['order'])
        
        return actions
    
    def _analyze_risks(self, text: str) -> Dict[str, List[str]]:
        """Metin iÃ§indeki risk alanlarÄ±nÄ± tespit et"""
        risks = {
            'CRITICAL': [],
            'HIGH': [],
            'MEDIUM': [],
            'LOW': []
        }
        
        text_lower = text.lower()
        
        for risk_level, keywords in self.risk_keywords.items():
            for keyword in keywords:
                if keyword.lower() in text_lower:
                    risks[risk_level].append(keyword)
        
        # Duplikat kaldÄ±r
        for level in risks:
            risks[level] = list(set(risks[level]))
        
        return risks
    
    def _analyze_sentiment(self, text: str) -> Dict[str, float]:
        """Metin sentimentini analiz et"""
        try:
            scores = self.sia.polarity_scores(text)
            return {
                'positive': scores['pos'],
                'negative': scores['neg'],
                'neutral': scores['neu'],
                'compound': scores['compound']
            }
        except Exception as e:
            print(f"âš ï¸ Sentiment analiz hatasÄ±: {e}")
            return {'positive': 0, 'negative': 0, 'neutral': 1, 'compound': 0}
    
    def _determine_test_types(self, text: str) -> List[str]:
        """Hangi test tÃ¼rlerinin gerekli olduÄŸunu belirle"""
        test_types = []
        text_lower = text.lower()
        
        # UI Test
        if any(kw in text_lower for kw in ['klik', 'click', 'arayÃ¼z', 'button', 'form', 'input', 'gÃ¶rÃ¼n']):
            test_types.append('UI')
        
        # API Test
        if any(kw in text_lower for kw in ['api', 'endpoint', 'request', 'response', 'json', 'rest']):
            test_types.append('API')
        
        # GÃ¼venlik Test
        if any(kw in text_lower for kw in ['gÃ¼venlik', 'security', 'ÅŸifre', 'password', 'token', 'auth', 'injection']):
            test_types.append('SECURITY')
        
        # Performans Test
        if any(kw in text_lower for kw in ['hÄ±z', 'speed', 'performance', 'yavaÅŸ', 'slow', 'timeout']):
            test_types.append('PERFORMANCE')
        
        # Entegrasyon Test
        if any(kw in text_lower for kw in ['entegrasyon', 'integration', 'baÄŸlantÄ±', 'connection', 'database', 'db']):
            test_types.append('INTEGRATION')
        
        return test_types if test_types else ['UI']
    
    def _identify_edge_cases(self, text: str) -> List[str]:
        """Edge case'leri otomatik tespit et"""
        edge_cases = []
        text_lower = text.lower()
        
        patterns = {
            'BOUNDARY': ['sÄ±nÄ±r', 'limit', 'max', 'min', 'maksimum', 'minimum'],
            'NULL': ['boÅŸ', 'empty', 'null', 'none', 'undefined'],
            'INVALID': ['geÃ§ersiz', 'invalid', 'hatalÄ±', 'wrong', 'incorrect'],
            'SPECIAL_CHARS': ['Ã¶zel karakter', 'special', 'simge', 'symbol'],
            'LARGE_DATA': ['bÃ¼yÃ¼k', 'large', 'heavy', 'massive'],
            'CONCURRENT': ['eÅŸzamanlÄ±', 'concurrent', 'parallel', 'aynÄ± anda'],
            'TIMEOUT': ['timeout', 'time out', 'uzun sÃ¼re'],
        }
        
        for case_type, keywords in patterns.items():
            for keyword in keywords:
                if keyword in text_lower:
                    edge_cases.append(f"{case_type}: {keyword}")
                    break
        
        # EÄŸer edge case yoksa standart olanlarÄ± ekle
        if not edge_cases:
            edge_cases = [
                'BOUNDARY: Min/Max values',
                'NULL: Empty/null inputs',
                'INVALID: Invalid data types'
            ]
        
        return edge_cases
    
    def _extract_user_flows(self, text: str) -> List[Dict[str, Any]]:
        """KullanÄ±cÄ± akÄ±ÅŸlarÄ±nÄ± metinden Ã§Ä±kar"""
        flows = []
        sentences = sent_tokenize(text)
        
        current_flow = {
            'steps': [],
            'actors': [],
            'description': ''
        }
        
        for sentence in sentences:
            # Yeni akÄ±ÅŸ varsa
            if any(kw in sentence.lower() for kw in ['flow', 'senaryo', 'scenario', 'process', 'workflow']):
                if current_flow['steps']:
                    flows.append(current_flow)
                current_flow = {
                    'steps': [],
                    'actors': [],
                    'description': sentence.strip()
                }
            
            # AdÄ±mlarÄ± ekle
            if any(kw in sentence.lower() for kw in ['then', 'sonra', 'after', 'when', 'eÄŸer', 'if']):
                current_flow['steps'].append(sentence.strip())
        
        if current_flow['steps']:
            flows.append(current_flow)
        
        return flows if flows else [{
            'description': 'Default Flow',
            'steps': [s.strip() for s in sentences[:3]]
        }]
    
    def generate_enhanced_scenarios(self, text: str, template: str = "text") -> List[Dict[str, Any]]:
        """
        GeliÅŸtirilmiÅŸ senaryo oluÅŸtur (Sembi IQ tarzÄ±)

        Args:
            text: Gereksinim metni
            template: 'text' veya 'bdd'

        Returns:
            GeliÅŸtirilmiÅŸ test senaryolarÄ±
        """
        # Ã–NCELÄ°KLE: Basit adÄ±m listesi kontrolÃ¼
        # EÄŸer metin satÄ±r satÄ±r basit adÄ±mlardan oluÅŸuyorsa, TEK SENARYO oluÅŸtur
        lines = [line.strip() for line in text.strip().split('\n') if line.strip()]

        # Basit adÄ±m listesi tespiti
        is_simple_step_list = (
            len(lines) >= 2 and
            len(lines) <= 10 and
            all(len(line) < 200 for line in lines) and  # Her satÄ±r kÄ±sa
            not any(keyword in text.lower() for keyword in [
                'senaryo', 'scenario', 'feature', 'given', 'when', 'then',
                'gereksinim', 'requirement', 'story', 'epic'
            ])
        )

        if is_simple_step_list:
            print(f"[NLP] ğŸ¯ Basit adÄ±m listesi tespit edildi ({len(lines)} adÄ±m), TEK SENARYO oluÅŸturuluyor...")

            # AdÄ±mlarÄ± oluÅŸtur
            steps = []
            for i, line in enumerate(lines, 1):
                steps.append({
                    "number": i,
                    "action": line
                })

            # BaÅŸlÄ±k: Ä°lk ve son adÄ±mdan oluÅŸtur
            if len(lines) >= 2:
                first_word = lines[0].split()[0] if lines[0].split() else "Test"
                last_word = lines[-1].split()[0] if lines[-1].split() else "Test"
                title = f"{first_word.capitalize()} - {last_word.capitalize()}"
            else:
                title = lines[0] if len(lines[0]) < 50 else "Test Senaryosu"

            scenario = {
                "title": title,
                "description": f"{len(lines)} adÄ±mlÄ± test senaryosu: " + " â†’ ".join(lines),
                "steps": steps,
                "expectedResult": "TÃ¼m adÄ±mlar baÅŸarÄ±yla tamamlanÄ±r",
                "priority": "MEDIUM",
                "automationType": "UI",
                "testData": {}
            }

            if template == "bdd":
                bdd_steps = "\n".join([f"    And {line}" if i > 0 else f"    When {line}" for i, line in enumerate(lines)])
                scenario["bddFormat"] = f"""Feature: {title}
  Scenario: {title}
    Given uygulama hazÄ±r
{bdd_steps}
    Then iÅŸlem baÅŸarÄ±lÄ± olur"""

            print(f"[NLP] âœ… Tek senaryo oluÅŸturuldu: {title}")
            return [scenario]

        # KarmaÅŸÄ±k metin analizi (eski yÃ¶ntem)
        print(f"[NLP] ğŸ” KarmaÅŸÄ±k metin analizi yapÄ±lÄ±yor...")
        analysis = self.analyze_requirements(text)

        scenarios = []

        # 1. Temel senaryolar (User Flows'tan)
        for i, flow in enumerate(analysis['user_flows']):
            scenario = self._create_scenario_from_flow(flow, template)
            scenarios.append(scenario)
        
        # 2. Risk-based senaryolar
        for risk_level, keywords in analysis['risks'].items():
            if keywords:
                scenario = self._create_risk_scenario(keywords, risk_level, template)
                scenarios.append(scenario)
        
        # 3. Edge case senaryolarÄ±
        for edge_case in analysis['edge_cases']:
            scenario = self._create_edge_case_scenario(edge_case, template)
            scenarios.append(scenario)
        
        # 4. Negatif test senaryolarÄ±
        negative_scenario = self._create_negative_scenario(analysis, template)
        scenarios.append(negative_scenario)
        
        # Duplikat kaldÄ±r
        unique_scenarios = []
        seen_titles = set()
        
        for scenario in scenarios:
            title_key = scenario['title'].lower()
            if title_key not in seen_titles:
                seen_titles.add(title_key)
                unique_scenarios.append(scenario)
        
        return unique_scenarios
    
    def _create_scenario_from_flow(self, flow: Dict, template: str) -> Dict[str, Any]:
        """KullanÄ±cÄ± akÄ±ÅŸÄ±ndan senaryo oluÅŸtur"""
        steps = []
        for i, step in enumerate(flow['steps'][:5], 1):  # Max 5 adÄ±m
            steps.append({
                'number': i,
                'action': step.strip()
            })
        
        scenario = {
            'title': flow.get('description', 'User Flow Scenario')[:50],
            'description': flow.get('description', 'Test based on user workflow'),
            'steps': steps,
            'expectedResult': 'Ä°ÅŸlem baÅŸarÄ±yla tamamlandÄ±',
            'priority': 'HIGH',
            'automationType': 'UI',
            'testData': {},
            'preconditions': 'KullanÄ±cÄ± oturum aÃ§mÄ±ÅŸ'
        }
        
        if template == "bdd":
            scenario['bddFormat'] = self._convert_to_bdd(scenario)
        
        return scenario
    
    def _create_risk_scenario(self, keywords: List[str], risk_level: str, template: str) -> Dict[str, Any]:
        """Risk tabanlÄ± senaryo oluÅŸtur"""
        priority_map = {
            'CRITICAL': 'CRITICAL',
            'HIGH': 'HIGH',
            'MEDIUM': 'MEDIUM',
            'LOW': 'LOW'
        }
        
        scenario = {
            'title': f'{risk_level} Risk Test: {keywords[0]}',
            'description': f'Test iÃ§in kritik alan: {", ".join(keywords)}',
            'steps': [
                {'number': 1, 'action': f'{keywords[0]} ile ilgili iÅŸlemi baÅŸlat'},
                {'number': 2, 'action': 'Sistem davranÄ±ÅŸÄ±nÄ± gÃ¶zlemle'},
                {'number': 3, 'action': 'GÃ¼venlik kontrolleri doÄŸrula'}
            ],
            'expectedResult': f'{risk_level} seviyesi iÃ§in uygun gÃ¼venlik saÄŸlanmÄ±ÅŸ',
            'priority': priority_map.get(risk_level, 'HIGH'),
            'automationType': 'UI',
            'testData': {'riskArea': keywords[0]},
            'preconditions': 'Sistem ayakta'
        }
        
        if template == "bdd":
            scenario['bddFormat'] = self._convert_to_bdd(scenario)
        
        return scenario
    
    def _create_edge_case_scenario(self, edge_case: str, template: str) -> Dict[str, Any]:
        """Edge case senaryo oluÅŸtur"""
        scenario = {
            'title': f'Edge Case: {edge_case[:40]}',
            'description': f'Edge case testi: {edge_case}',
            'steps': [
                {'number': 1, 'action': f'{edge_case} koÅŸullarÄ±nÄ± hazÄ±rla'},
                {'number': 2, 'action': 'Ä°ÅŸlemi Ã§alÄ±ÅŸtÄ±r'},
                {'number': 3, 'action': 'Sistem doÄŸru davranÄ±ÅŸ gÃ¶steriyor mu?'}
            ],
            'expectedResult': "Sistem edge case'i doÄŸru iÅŸler",
            'priority': 'MEDIUM',
            'automationType': 'UI',
            'testData': {'edgeCase': edge_case},
            'preconditions': 'Sistem hazÄ±r'
        }
        
        if template == "bdd":
            scenario['bddFormat'] = self._convert_to_bdd(scenario)
        
        return scenario
    
    def _create_negative_scenario(self, analysis: Dict, template: str) -> Dict[str, Any]:
        """Negatif test senaryo oluÅŸtur"""
        scenario = {
            'title': 'Negatif Test Senaryosu',
            'description': 'HatalÄ± veya geÃ§ersiz girdilerle sistem davranÄ±ÅŸÄ±nÄ± test et',
            'steps': [
                {'number': 1, 'action': 'GeÃ§ersiz veriler gir'},
                {'number': 2, 'action': 'Ä°ÅŸlemi baÅŸlat'},
                {'number': 3, 'action': 'Hata mesajÄ± kontrol et'}
            ],
            'expectedResult': 'Sistem uygun hata mesajÄ± gÃ¶steriyor',
            'priority': 'HIGH',
            'automationType': 'UI',
            'testData': {'invalid': True, 'errorExpected': True},
            'preconditions': 'Sistem ayakta'
        }
        
        if template == "bdd":
            scenario['bddFormat'] = self._convert_to_bdd(scenario)
        
        return scenario
    
    def _convert_to_bdd(self, scenario: Dict) -> str:
        """Senaryoyu BDD formatÄ±na Ã§evir"""
        title = scenario['title']
        steps = scenario['steps']
        expected = scenario['expectedResult']
        
        bdd = f"""Feature: {title}
  Scenario: {title}
    Given sistem baÅŸlatÄ±lmÄ±ÅŸ
"""
        
        for step in steps:
            bdd += f"    When {step['action']}\n"
        
        bdd += f"    Then {expected}"
        
        return bdd


# Singleton instance
nlp_analyzer = NLPAnalyzer()


if __name__ == '__main__':
    # Test
    test_text = """
    KullanÄ±cÄ± sisteme email ve ÅŸifre ile giriÅŸ yapar.
    HatalÄ± bir ÅŸifre girilse hata mesajÄ± gÃ¶sterilir.
    GeÃ§erli giriÅŸ bilgileri ile kullanÄ±cÄ± ana sayfaya yÃ¶nlendirilir.
    GÃ¼venlik protokolleri kontrol edilir.
    """
    
    analyzer = NLPAnalyzer()
    analysis = analyzer.analyze_requirements(test_text)
    scenarios = analyzer.generate_enhanced_scenarios(test_text)
    
    print("=== ANALYSIS ===")
    print(f"Entities: {analysis['entities']}")
    print(f"Actions: {analysis['actions']}")
    print(f"Risks: {analysis['risks']}")
    print(f"Test Types: {analysis['test_types']}")
    print(f"\n=== GENERATED SCENARIOS ===")
    for i, scenario in enumerate(scenarios, 1):
        print(f"\n{i}. {scenario['title']}")
        print(f"   Priority: {scenario['priority']}")
        print(f"   Steps: {len(scenario['steps'])}")
